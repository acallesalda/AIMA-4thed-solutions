{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "\n",
    "Define in your own words: (a) intelligence, (b) artificial intelligence, (c) agent, (d) rationality, (e) logical reasoning.\n",
    "\n",
    "## Answer\n",
    "\n",
    "- __Intelligence__: A mechanism by which an agent manipulated outward information in order to meet a certain goal.\n",
    "- __Artificial Intelligence__: Methods for making machines act intelligently: i.e., make sensible decisions in order to meet cetain goals. This methods are not programmed explicitly in the machine.\n",
    "- __Agent__: An entity which tries to meet cetain goals for a given problem.\n",
    "- __Rationality__: The ability to reflect and give reasons for choosing between different alternatives.\n",
    "- __Logical Reasoning__: A type of reasoning that must follow a given set of rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "\n",
    "Read Turing’s original paper on AI Turing:1950 .In the paper, he discusses several objections to his proposed enterprise and his test for intelligence. Which objections still carry weight? Are his refutations valid? Can you think of new objections arising from developments since he wrote the paper? In the paper, he predicts that, by the year 2000, a computer will have a 30% chance of passing a five-minute Turing Test with an unskilled interrogator. What chance do you think a computer would have today? In another 50 years?\n",
    "\n",
    "# Answer\n",
    "\n",
    "## Objections\n",
    "\n",
    "- The theological objection carries little weight. There is no place for such an objection in modern science. His refutation is kind of weird, but it makes sense as he was trying to refute it theologically also.\n",
    "- The 'heads in the sand' objection. There are still some concerns regarding machines that could achieve human-like intelligence, and their possible dangers. I don't think this is addressed properly by Turing. \n",
    "- The mathematical objection. It is a valid concern, even today, but I think Turing refutes the notion interestingly.\n",
    "- The argument from consciousness. A valid concer, but a bit solipsist as Turing argues. However, we still don't know much about consiousness. This should have been discussed more.\n",
    "- Arguments from various disabilities. I agree with Turing, this are largely arbitrary concern and without much base.\n",
    "- Lady Lovelace objection: This does not carry weight today because of modern methods where you do not program things explicitly, i.e., machine learning.\n",
    "- Argument from continuity in the Nervous system: I agree with Turing, the difference between continuous/discrete does not mean one is intelligent and the other is not.\n",
    "- Argument from informality of behaviour. This is not true, as we can see that many ML models can generalize.\n",
    "- Arguments from extra sensory perception. This absolutely does not hold today. Is Turing being tounge in cheek? Maybe the evidence for ESP back then was different and Turing was misled to believe it was true.\n",
    "\n",
    "## Predictions\n",
    "\n",
    "I think computers now have much greater chances of passing the Turing test, maybe like $40-45\\%$ or maybe nearning $50\\%$. In another $50$ years computers will most probably get very near $50\\%$ of chances for passing the Turing Test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "\n",
    "Every year the Loebner Prize is awarded to the program that comes closest to passing a version of the Turing Test. Research and report on the latest winner of the Loebner prize. What techniques does it use? How does it advance the state of the art in AI?\n",
    "\n",
    "## Answer\n",
    "\n",
    "Kuki has won the Loebner prize like $5$ times in a row. It uses a rule based system, improved with reinforcment learning. I think it advances the state of the art but for conversational AI specifically, not the area as a whole. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. \n",
    "\n",
    "Are reflex actions (such as flinching from a hot stove) rational? Are they intelligent?\n",
    "\n",
    "## Answer\n",
    "\n",
    "They are 'limited-rational' because they are appropiate actions within a limited time. I would call them intelligent, since an AI should be able to take those quick decisions in order to avoid critical harm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.\n",
    "\n",
    "There are well-known classes of problems that are intractably difficult for computers, and other classes that are provably undecidable. Does this mean that AI is impossible?\n",
    "\n",
    "## Answer\n",
    "\n",
    "No. For this to be true we would have first to discover how consiousness works algorithmically, and then show that it is an untractable or undecidable problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. \n",
    "\n",
    "Suppose we extend Evans’s SYSTEM program so that it can score 200 on a standard IQ test. Would we then have a program more intelligent than a human? Explain.\n",
    "\n",
    "## Answer\n",
    "\n",
    "No. We would have a program that is good at solving IQ test and nothing more. It would not be useful for anything else. Intelligence implies being able to perform well in a wide variety of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.\n",
    "\n",
    "The neural structure of the sea slug Aplysis has been widely studied (first by Nobel Laureate Eric Kandel) because it has only about 20,000 neurons, most of them large and easily manipulated. Assuming that the cycle time for an Aplysis neuron is roughly the same as for a human neuron, how does the computational power, in terms of memory updates per second, compare with the high-end computer described in (Figure 1.3)?\n",
    "\n",
    "## Answer\n",
    "\n",
    "|                          |                          |\n",
    "| -------------------------|--------------------------|\n",
    "| Computational units      | $20000$ neurons          |\n",
    "| Storage Units            | $20000$ neurons          |\n",
    "|                          | $20'000.000$ synapses    |\n",
    "| Cycle Time               | $10^{-3}$                |\n",
    "| Operations/sec           | $2 * 10^{10}$            |\n",
    "| Memory updates/sec       | $2 * 10^7$               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. \n",
    "\n",
    "How could introspection—reporting on one’s inner thoughts—be inaccurate? Could I be wrong about what I’m thinking? Discuss.\n",
    "\n",
    "## Answer.\n",
    "\n",
    "Introspection can be really inaccurate. We are very emotional beings, and our inner thougths can be greatly biased by those emotions, which may make us see false statements as true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. \n",
    "\n",
    "To what extent are the following computer systems instances of artificial intelligence:\n",
    "- Supermarket bar code scanners.\n",
    "- Web search engines.\n",
    "- Voice-activated telephone menus.\n",
    "- Internet routing algorithms that respond dynamically to the state of the network.\n",
    "\n",
    "## Answer\n",
    "\n",
    "- Supermarket barcode scanner: No artificial intelligence, just different representations of the same thing (the product name).\n",
    "- Websearch engine: Largely uses artificial intelligence to know which pages are more relevant for the query.\n",
    "- Voice-activated telephone menus: Voice recognition is an area of AI so clearly yes.\n",
    "- Internet routing algorithms that respond dynamically to the state of the network: Clearly uses AI, as it responds to changes in the enviroment to make appropriate decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.\n",
    "\n",
    "The question is repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. \n",
    "\n",
    "Many of the computational models of cognitive activities that have been proposed involve quite complex mathematical operations, such as convolving an image with a Gaussian or finding a minimum of the entropy function. Most humans (and certainly all animals) never learn this kind of mathematics at all, almost no one learns it before college, and almost no one can compute the convolution of a function with a Gaussian in their head. What sense does it make to say that the “vision system” is doing this kind of mathematics, whereas the actual person has no idea how to do it?\n",
    "\n",
    "## Answer\n",
    "\n",
    "I think we know little about the brain's inner function so we may not actually know how our 'vision system' works algorithmically speaking. So when we are designing computer vision systems, reimplementing our vision system is not feasible, so we just use methods that work in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.\n",
    "\n",
    "Some authors have claimed that perception and motor skills are the most important part of intelligence, and that “higher level” capacities are necessarily parasitic—simple add-ons to these underlying facilities. Certainly, most of evolution and a large part of the brain have been devoted to perception and motor skills, whereas AI has found tasks such as game playing and logical inference to be easier, in many ways, than perceiving and acting in the real world. Do you think that AI’s traditional focus on higher-level cognitive abilities is misplaced?\n",
    "\n",
    "## Answer\n",
    "\n",
    "No, I think it is not entirely missplaced. Even with this easier problem of higher-level cognitive abilities, we haven't reached human level performance for an abundance of tasks. Maybe when we do, we can focus entirely on the different -and more difficult- problem of perception and motor skill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.\n",
    "\n",
    "Why would evolution tend to result in systems that act rationally? What goals are such systems designed to achieve?\n",
    "\n",
    "## Answer\n",
    "\n",
    "If systems that act rationally are fitter than systems that do not act rationally, then evolution will tend to result in systems that act rationally. These systems can achieve many different goals. It is really problem dependent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. \n",
    "\n",
    "Is AI a science, or is it engineering? Or neither or both? Explain.\n",
    "\n",
    "## Answer\n",
    "\n",
    "Both. It has benefited from formalization and rigor (science) and from trial and error experimentation (engineering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.\n",
    "\n",
    "“Surely computers cannot be intelligent—they can do only what their programmers tell them.” Is the latter statement true, and does it imply the former?\n",
    "\n",
    "## Answer\n",
    "\n",
    "This is Ada Lovelace's objection. Already addressed in 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.\n",
    "\n",
    "“Surely animals cannot be intelligent—they can do only what their genes tell them.” Is the latter statement true, and does it imply the former?\n",
    "\n",
    "# Answer\n",
    "\n",
    "This can be answered the same as 1.15, as in Turing's refutation of Ada Lovelace's objection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. \n",
    "\n",
    "“Surely animals, humans, and computers cannot be intelligent—they can do only what their constituent atoms are told to do by the laws of physics.” Is the latter statement true, and does it imply the former?\n",
    "\n",
    "## Answer\n",
    "\n",
    "Same as 1.15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. \n",
    "\n",
    "Examine the AI literature to discover whether the following tasks can currently be solved by computers: - Playing a decent game of table tennis (Ping-Pong). - Driving in the center of Cairo, Egypt. - Driving in Victorville, California. - Buying a week’s worth of groceries at the market. - Buying a week’s worth of groceries on the Web. - Playing a decent game of bridge at a competitive level. - Discovering and proving new mathematical theorems. - Writing an intentionally funny story. - Giving competent legal advice in a specialized area of law. - Translating spoken English into spoken Swedish in real time. - Performing a complex surgical operation.\n",
    "\n",
    "## Answer\n",
    "\n",
    "- Playing a decent game of ping-pong: Solved.\n",
    "- Driving in the center of Cairo, Egypt: Unsolved.\n",
    "- Driving in Victorville, California: Solved.\n",
    "- Buying a week's worth of groceries at the market: Solid progress.\n",
    "- Buying a week's worth of groceries on the web: Solved.\n",
    "- Playing a decent game of bridge at a competitive level: Solved.\n",
    "- Discovering and proving new mathematical theorems: Solved.\n",
    "- Writing an intentionally funny story: Minor progress.\n",
    "- Giving competent legal advice in a specilized area of law: Minor progress.\n",
    "- Translating spoken English into spoken swedish in real time: Solid progress.\n",
    "- Performing a complex surgical operation: At the most doctors will use AI assistants, not AI operating themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19.\n",
    "\n",
    "For the currently infeasible tasks, try to find out what the difficulties are and predict when, if ever, they will be overcome.\n",
    "\n",
    "## Answer\n",
    "\n",
    "- For driving in the center of Cairo, an AI must be trained from massive historical data in that specific place in order for it to learn the local driving customs. I'll give it $20$ years.\n",
    "- For buying a week worth of groceries, the main problem are perception and locomotion, which are hard. I give it $50$ years.\n",
    "- For writing an intentionally funny story there is some problems. NLP models seem better each day. But things like style/humour are not yet understood by them. Should be $10$-$20$ years.\n",
    "- With the advent of good NLP models, an AI that can give competent legal advice seems inevitable. I give it $10$ years.\n",
    "- Real time spoken english into swedish is possible now, but it is not perfect. Audio translation models can only get better with the years. I give it $10$ years.\n",
    "- Surgical operations require very precise movements, which is exactly where AI is not very good at. I-ll give it $70$ years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20.\n",
    "\n",
    "Various subfields of AI have held contests by defining a standard task and inviting researchers to do their best. Examples include the DARPA Grand Challenge for robotic cars, the International Planning Competition, the Robocup robotic soccer league, the TREC information retrieval event, and contests in machine translation and speech recognition. Investigate five of these contests and describe the progress made over the years. To what degree have the contests advanced the state of the art in AI? To what degree do they hurt the field by drawing energy away from new ideas?\n",
    "\n",
    "## Answer\n",
    "\n",
    "- DARPA Grand challange for robotic cars: The first year no car was able to finish the race, but the second year some cars could. It advanced knowledge for automated driving.\n",
    "- International planning competition: A great variety of planning benchmarks, algorithms, methods and problems have been posed by the competition throughout the years, so I would say this is able to advance the state of the art quite well, at least in AI for planning.\n",
    "- Robocup robotic soccer league: The teams of robots are still in their infancy. Perception and locomotion for something as complex and dynamic as soccer is just not there. Does not seem to have aided to the state of the art much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
