{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "\n",
    "Define in your own words: (a) intelligence, (b) artificial intelligence, (c) agent, (d) rationality, (e) logical reasoning.\n",
    "\n",
    "## Answer\n",
    "\n",
    "- __Intelligence__: A mechanism by which an agent manipulated outward information in order to meet a certain goal.\n",
    "- __Artificial Intelligence__: Methods for making machines act intelligently: i.e., make sensible decisions in order to meet cetain goals. This methods are not programmed explicitly in the machine.\n",
    "- __Agent__: An entity which tries to meet cetain goals for a given problem.\n",
    "- __Rationality__: The ability to reflect and give reasons for choosing between different alternatives.\n",
    "- __Logical Reasoning__: A type of reasoning that must follow a given set of rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. \n",
    "\n",
    "Read Turingâ€™s original paper on AI Turing:1950 .In the paper, he discusses several objections to his proposed enterprise and his test for intelligence. Which objections still carry weight? Are his refutations valid? Can you think of new objections arising from developments since he wrote the paper? In the paper, he predicts that, by the year 2000, a computer will have a 30% chance of passing a five-minute Turing Test with an unskilled interrogator. What chance do you think a computer would have today? In another 50 years?\n",
    "\n",
    "# Answer\n",
    "\n",
    "## Objections\n",
    "\n",
    "- The theological objection carries little weight. There is no place for such an objection in modern science. His refutation is kind of weird, but it makes sense as he was trying to refute it theologically also.\n",
    "- The 'heads in the sand' objection. There are still some concerns regarding machines that could achieve human-like intelligence, and their possible dangers. I don't think this is addressed properly by Turing. \n",
    "- The mathematical objection. It is a valid concern, even today, but I think Turing refutes the notion interestingly.\n",
    "- The argument from consciousness. A valid concer, but a bit solipsist as Turing argues. However, we still don't know much about consiousness. This should have been discussed more.\n",
    "- Arguments from various disabilities. I agree with Turing, this are largely arbitrary concern and without much base.\n",
    "- Lady Lovelace objection: This does not carry weight today because of modern methods where you do not program things explicitly, i.e., machine learning.\n",
    "- Argument from continuity in the Nervous system: I agree with Turing, the difference between continuous/discrete does not mean one is intelligent and the other is not.\n",
    "- Argument from informality of behaviour. This is not true, as we can see that many ML models can generalize.\n",
    "- Arguments from extra sensory perception. This absolutely does not hold today. Is Turing being tounge in cheek? Maybe the evidence for ESP back then was different and Turing was misled to believe it was true.\n",
    "\n",
    "## Predictions\n",
    "\n",
    "I think computers now have much greater chances of passing the Turing test, maybe like $40-45\\%$ or maybe nearning $50\\%$. In another $50$ years computers will most probably get very near $50\\%$ of chances for passing the Turing Test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.\n",
    "\n",
    "Every year the Loebner Prize is awarded to the program that comes closest to passing a version of the Turing Test. Research and report on the latest winner of the Loebner prize. What techniques does it use? How does it advance the state of the art in AI?\n",
    "\n",
    "## Answer\n",
    "\n",
    "Kuki has won the Loebner prize like $5$ times in a row. It uses a rule based system, improved with reinforcment learning. I think it advances the state of the art but for conversational AI specifically, not the area as a whole. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. \n",
    "\n",
    "Are reflex actions (such as flinching from a hot stove) rational? Are they intelligent?\n",
    "\n",
    "## Answer\n",
    "\n",
    "They are 'limited-rational' because they are appropiate actions within a limited time. I would call them intelligent, since an AI should be able to take those quick decisions in order to avoid critical harm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
